{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78cd9c8f-ef3f-4037-9012-cc1ec12cdbee",
   "metadata": {},
   "source": [
    "Project goals:\n",
    "- Scrape laptop data from Takealot and Amazon sites to find arbitrage opportunities (for laptops between R10000 and R20000).\n",
    "- Process must be automated.\n",
    "- Output must be dataframe of laptop brand, name, price, stock-status if available (in/out of stock), and link to laptop info for both sites. Laptops will get matched on similarity based on a selected matching ratio (90%), which will also be included in the final output, to compensate for slight naming differences on both sites.\n",
    "- Disclaimer: this project was not designed for practical use.\n",
    "\n",
    "The following is the relevant code to produce this output (should take about 10 minutes to run - need to investigate how I can significantly reduce it):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d45974d-125d-481d-b2d9-240ed2cd86d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Name_takealot</th>\n",
       "      <th>Price_takealot</th>\n",
       "      <th>Stock status_takealot</th>\n",
       "      <th>Link_takealot</th>\n",
       "      <th>Name_amazon</th>\n",
       "      <th>Price_amazon</th>\n",
       "      <th>Stock status_amazon</th>\n",
       "      <th>Link_amazon</th>\n",
       "      <th>Match Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Huawei</td>\n",
       "      <td>Huawei MateBook D16 Intel Core i5-13420H 16GB ...</td>\n",
       "      <td>R 16,999</td>\n",
       "      <td>In stockJHBThis item can be shipped from Johan...</td>\n",
       "      <td>https://www.takealot.com/huawei-matebook-d16-i...</td>\n",
       "      <td>Huawei MateBook D16 Intel Core i5-13420H 16GB ...</td>\n",
       "      <td>R 14 999,</td>\n",
       "      <td>click link to view</td>\n",
       "      <td>https://www.amazon.co.za/Huawei-MateBook-Intel...</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HP</td>\n",
       "      <td>HP 15S Core I7-1355U 16GB 512GB SSD Windows 11...</td>\n",
       "      <td>R 14,899</td>\n",
       "      <td>No stock</td>\n",
       "      <td>https://www.takealot.com/hp-15s-core-i7-1355u-...</td>\n",
       "      <td>HP 15S Core I7-1355U 16GB 512GB SSD Windows 11...</td>\n",
       "      <td>R 14 899,</td>\n",
       "      <td>click link to view</td>\n",
       "      <td>https://www.amazon.co.za/HP-I7-1355U-512GB-Win...</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dell</td>\n",
       "      <td>DELL INSPIRON 3520 | i5 12th gen | 32GB | 512G...</td>\n",
       "      <td>R 15,299</td>\n",
       "      <td>In stockCPTThis item can be shipped from Cape ...</td>\n",
       "      <td>https://www.takealot.com/dell-inspiron-3520-i5...</td>\n",
       "      <td>DELL INSPIRON 3520 | i5 12th gen | 32GB | 512G...</td>\n",
       "      <td>R 15 299,</td>\n",
       "      <td>click link to view</td>\n",
       "      <td>https://www.amazon.co.za/DELL-INSPIRON-3520-51...</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS</td>\n",
       "      <td>ASUS Vivobook 16 13th gen i5 | 24GB | 512GB NV...</td>\n",
       "      <td>R 15,299</td>\n",
       "      <td>Ships in 4 - 6 work days</td>\n",
       "      <td>https://www.takealot.com/asus-vivobook-16-13th...</td>\n",
       "      <td>ASUS Vivobook 16 13th gen i5 | 24GB | 512GB NV...</td>\n",
       "      <td>R 13 999,</td>\n",
       "      <td>click link to view</td>\n",
       "      <td>https://www.amazon.co.za/ASUS-Vivobook-13th-51...</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS</td>\n",
       "      <td>ASUS Vivobook Intel Core i7-13620H 8GB 512GB S...</td>\n",
       "      <td>R 13,499</td>\n",
       "      <td>In stockCPTThis item can be shipped from Cape ...</td>\n",
       "      <td>https://www.takealot.com/asus-vivobook-intel-c...</td>\n",
       "      <td>ASUS Vivobook Intel® Core™ i7-13620H 8GB RAM 5...</td>\n",
       "      <td>R 13 499,</td>\n",
       "      <td>click link to view</td>\n",
       "      <td>https://www.amazon.co.za/ASUS-Vivobook-Intel%C...</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MSI</td>\n",
       "      <td>MSI Thin 15 i5-12450H 32GB 512GB SSD RTX 2050 ...</td>\n",
       "      <td>R 16,499</td>\n",
       "      <td>In stockCPTThis item can be shipped from Cape ...</td>\n",
       "      <td>https://www.takealot.com/msi-thin-15-i5-12450h...</td>\n",
       "      <td>MSI Thin 15 i5-12450H 32GB 512GB SSD RTX 2050 ...</td>\n",
       "      <td>R 15 999,</td>\n",
       "      <td>click link to view</td>\n",
       "      <td>https://www.amazon.co.za/MSI-i5-12450H-512GB-G...</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Brand                                      Name_takealot Price_takealot  \\\n",
       "0  Huawei  Huawei MateBook D16 Intel Core i5-13420H 16GB ...       R 16,999   \n",
       "1      HP  HP 15S Core I7-1355U 16GB 512GB SSD Windows 11...       R 14,899   \n",
       "2    Dell  DELL INSPIRON 3520 | i5 12th gen | 32GB | 512G...       R 15,299   \n",
       "3    ASUS  ASUS Vivobook 16 13th gen i5 | 24GB | 512GB NV...       R 15,299   \n",
       "4    ASUS  ASUS Vivobook Intel Core i7-13620H 8GB 512GB S...       R 13,499   \n",
       "5     MSI  MSI Thin 15 i5-12450H 32GB 512GB SSD RTX 2050 ...       R 16,499   \n",
       "\n",
       "                               Stock status_takealot  \\\n",
       "0  In stockJHBThis item can be shipped from Johan...   \n",
       "1                                           No stock   \n",
       "2  In stockCPTThis item can be shipped from Cape ...   \n",
       "3                           Ships in 4 - 6 work days   \n",
       "4  In stockCPTThis item can be shipped from Cape ...   \n",
       "5  In stockCPTThis item can be shipped from Cape ...   \n",
       "\n",
       "                                       Link_takealot  \\\n",
       "0  https://www.takealot.com/huawei-matebook-d16-i...   \n",
       "1  https://www.takealot.com/hp-15s-core-i7-1355u-...   \n",
       "2  https://www.takealot.com/dell-inspiron-3520-i5...   \n",
       "3  https://www.takealot.com/asus-vivobook-16-13th...   \n",
       "4  https://www.takealot.com/asus-vivobook-intel-c...   \n",
       "5  https://www.takealot.com/msi-thin-15-i5-12450h...   \n",
       "\n",
       "                                         Name_amazon Price_amazon  \\\n",
       "0  Huawei MateBook D16 Intel Core i5-13420H 16GB ...    R 14 999,   \n",
       "1  HP 15S Core I7-1355U 16GB 512GB SSD Windows 11...    R 14 899,   \n",
       "2  DELL INSPIRON 3520 | i5 12th gen | 32GB | 512G...    R 15 299,   \n",
       "3  ASUS Vivobook 16 13th gen i5 | 24GB | 512GB NV...    R 13 999,   \n",
       "4  ASUS Vivobook Intel® Core™ i7-13620H 8GB RAM 5...    R 13 499,   \n",
       "5  MSI Thin 15 i5-12450H 32GB 512GB SSD RTX 2050 ...    R 15 999,   \n",
       "\n",
       "  Stock status_amazon                                        Link_amazon  \\\n",
       "0  click link to view  https://www.amazon.co.za/Huawei-MateBook-Intel...   \n",
       "1  click link to view  https://www.amazon.co.za/HP-I7-1355U-512GB-Win...   \n",
       "2  click link to view  https://www.amazon.co.za/DELL-INSPIRON-3520-51...   \n",
       "3  click link to view  https://www.amazon.co.za/ASUS-Vivobook-13th-51...   \n",
       "4  click link to view  https://www.amazon.co.za/ASUS-Vivobook-Intel%C...   \n",
       "5  click link to view  https://www.amazon.co.za/MSI-i5-12450H-512GB-G...   \n",
       "\n",
       "   Match Similarity  \n",
       "0             100.0  \n",
       "1             100.0  \n",
       "2             100.0  \n",
       "3             100.0  \n",
       "4              94.0  \n",
       "5             100.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import relevant libraries\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, WebDriverException, StaleElementReferenceException\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Starting WebDriver Session\n",
    "# If you don't want the page (GUI - Graphical User Interface) to show up, you can run...\n",
    "# the following code (recommended when system is fully automated - will cut down on...\n",
    "# computational expenses):\n",
    "\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\") # Run without popping up GUI\n",
    "# set options parameter in 'driver' object to options object during instantiation\n",
    "\n",
    "# Initializing firefox webdriver\n",
    "driver = webdriver.Firefox(options)\n",
    "\n",
    "# DEFINING A FUNCTION THAT WILL OUTPUT TABLE WITH TAKEALOT LAPTOP DATA\n",
    "\n",
    "def get_takealot_laptop():\n",
    "    \n",
    "    # open the desired URL\n",
    "    driver.get(\"https://www.takealot.com\")\n",
    "    \n",
    "    # wait for URL to load\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Interacting with input field using By module and find_element() method\n",
    "    #input_field = driver.find_element(By.NAME, \"search\") # Finding search box\n",
    "    input_field = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.NAME, \"search\"))\n",
    "    )\n",
    "    input_field.send_keys('laptop') # Writing 'laptop' as search input in search box\n",
    "    \n",
    "    # Submitting inputted keys \n",
    "    input_field.submit()\n",
    "    \n",
    "    # wait for laptop options to load\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # While loop to load all laptops by repeatedly clicking the 'Load More' button until all the options are laoded\n",
    "    while True:\n",
    "        # try block will attempt to find and click 'Load More' button while it is findable or not stale\n",
    "        try:\n",
    "            # Count items on page before clicking 'Load More'\n",
    "            current_count = len(driver.find_elements(By.CSS_SELECTOR, \"div.search-product\"))\n",
    "            \n",
    "            # Finding the 'Load More' button\n",
    "            #load_more_button = driver.find_element(By.XPATH, \"//button[text()='Load More']\")\n",
    "            load_more_button = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"//button[text()='Load More']\"))\n",
    "            )\n",
    "            # Scroll the element into view\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView();\", load_more_button)\n",
    "            # Using ActionChanins() class to simulate/automate actions taken to click on the 'Load More button'\n",
    "            ActionChains(driver).move_to_element(load_more_button).click(load_more_button).perform()\n",
    "\n",
    "            # Wait for items on page to increase (signal that page has loaded) before re-iterating loop\n",
    "            WebDriverWait(driver, 20).until(\n",
    "                lambda d: len(d.find_elements(By.CSS_SELECTOR, \"div.search-product\")) > current_count)\n",
    "                    \n",
    "        # If 'Load More' button doesn't show up within the exception's default time, break\n",
    "        # This is a check to see if 'Load More' button is actually gone if item count doesn't change\n",
    "        except TimeoutException as e:\n",
    "            if not driver.find_elements(By.XPATH, \"//button[text()='Load More']\"):\n",
    "                break\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    # Extract html of current page and store it in an object\n",
    "    html_takealot = driver.page_source\n",
    "    \n",
    "    # close currently opened tab\n",
    "    #driver.close()\n",
    "            \n",
    "    # Prettyfying the html\n",
    "    soup_takealot = BeautifulSoup(html_takealot, 'lxml')\n",
    "    \n",
    "    # CREATING A FOR-LOOP THAT WILL EXTRACT LAPTOP DETAILS WITHIN A PRICE RANGE OF R10000 AND R20000, THEN...\n",
    "    # STORE THEM AS A DATAFRAME\n",
    "\n",
    "    # initialize an empty list to store the Amazon laptop data\n",
    "    takealot_data = []\n",
    "\n",
    "    # extracting details for all laptops\n",
    "    laptops_details = soup_takealot.find_all('div', class_ = 'search-product grid')\n",
    "    # grid-y gap-1 product-card-module_product-details-container_3ntEA\n",
    "\n",
    "    # Define price range\n",
    "    min_price = 10000\n",
    "    max_price = 20000\n",
    "\n",
    "    # for-loop\n",
    "    for laptop_deets in laptops_details:\n",
    "        # extracting laptop name from 'laptop_details' object\n",
    "        # .text if you just want the text\n",
    "        name = laptop_deets.find('h4', class_ = 'product-card-module_product-title_16xh8')\n",
    "        name = name.text if name else \"None\"\n",
    "        # extracting laptop brand from 'laptop_details' object\n",
    "        brand = laptop_deets.find('a', href=re.compile(r'Brand'))\n",
    "        brand = brand.text if brand else \"None\"\n",
    "        # extracting text and numerical (for subsetting) laptop price from 'laptop_details' object\n",
    "        price = laptop_deets.find('span', class_ = 'currency plus currency-module_currency_29IIm')\n",
    "        price_text = price.text if price else \"None\"\n",
    "        if price:\n",
    "            price_stripped = re.sub(r'\\D', '', price.text)\n",
    "            price_numerical = int(price_stripped)\n",
    "        # extracting laptop stock status from 'laptop_details' object\n",
    "        stock_status = laptop_deets.find('div', class_ = 'grid-y gap-1 in-stock-indicator-module_in-stock-indicator_3kr9C')\n",
    "        stock_status = stock_status.text if stock_status and stock_status.text else \"No stock\"\n",
    "        # extracting link for laptop\n",
    "        link = laptop_deets.find('a', class_ = 'product-card-module_link-underlay_3sfaA')\n",
    "        link = 'https://www.takealot.com' + link.get('href') if link else \"No link\"\n",
    "\n",
    "        # Filter laptops within price range and create dictionary output\n",
    "        if price and min_price <= price_numerical <= max_price:\n",
    "            #print(f'''\n",
    "            #Name: {name}\n",
    "            #Brand: {brand}\n",
    "            #Price: {price_text}\n",
    "            #Stock status: {stock_status}\n",
    "            #Link: {link}\n",
    "            #''')\n",
    "            takealot_data.append({\n",
    "                'Brand': brand,\n",
    "                'Name': name,\n",
    "                'Price': price_text,\n",
    "                'Stock status': stock_status,\n",
    "                'Link': link\n",
    "            })\n",
    "\n",
    "            # print line space as separator between laptop details\n",
    "            #print('')\n",
    "\n",
    "    # convert list of dictionaries into a Pandas dataframe\n",
    "    takealot_df = pd.DataFrame(takealot_data)\n",
    "\n",
    "    # return the dataframe\n",
    "    return takealot_df\n",
    "\n",
    "# run function (will take some time)\n",
    "takealot_laptop = get_takealot_laptop()\n",
    "\n",
    "# DEFINING A FUNCTION THAT WILL OUTPUT TABLE WITH AMAZON LAPTOP DATA\n",
    "\n",
    "def get_amazon_laptop():\n",
    "    \n",
    "    # open the desired URL\n",
    "    driver.get(\"https://www.amazon.co.za\")\n",
    "    \n",
    "    # wait for URL to load\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Interacting with input field using By module and find_element() method\n",
    "    # Finding search box\n",
    "    #input_field = driver.find_element(By.NAME, \"field-keywords\")\n",
    "    input_field = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.NAME, \"field-keywords\"))\n",
    "    )\n",
    "    # Writing 'laptop' as search input in search box\n",
    "    input_field.send_keys('laptop')\n",
    "    \n",
    "    # Submitting inputted keys \n",
    "    input_field.submit()\n",
    "    \n",
    "    # wait for URL to load\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Initialize empty object where Amazon html will be contained\n",
    "    html_amazon = []\n",
    "\n",
    "    # While loop to iterate through pages by pressing the 'next' button then scraping html on current page\n",
    "    while True:\n",
    "        try:\n",
    "            # Scrape the current page's html and add it to the 'html_amazon' object with a page delimiter\n",
    "            html_amazon.append(driver.page_source)\n",
    "\n",
    "            # Get current page number\n",
    "            current_page = driver.find_element(By.CSS_SELECTOR, \"span.s-pagination-item.s-pagination-selected\").text\n",
    "\n",
    "            # waiting 10 seconds maximum for next button to become clickable and assigning it to an object once found\n",
    "            next_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, \"//a[contains(@class, 's-pagination-next')]\"))\n",
    "            )\n",
    "            # If 'next_button' is disabled, break the loop\n",
    "            if \"disabled\" in next_button.get_attribute(\"class\") or next_button.get_attribute(\"aria-disabled\") == \"true\":\n",
    "                #print(\"No more pages\")\n",
    "                break\n",
    "            # Scrolling the next button into view (specifically center view)\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", next_button)\n",
    "            # Using ActionChanins() class to simulate/automate actions taken to click on the 'Load More button'\n",
    "            ActionChains(driver).move_to_element(next_button).click(next_button).perform()\n",
    "\n",
    "            # Wait until page number changes\n",
    "            WebDriverWait(driver, 20).until(\n",
    "                lambda d: d.find_element(By.CSS_SELECTOR, \"span.s-pagination-item.s-pagination-selected\").text != current_page)\n",
    "\n",
    "            # Wait until results are present\n",
    "            WebDriverWait(driver, 20).until(\n",
    "                EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"div[data-component-type='s-search-result']\")))\n",
    "\n",
    "        # If 'Next' button doesn't show up within the exception's default time, break\n",
    "        except TimeoutException as e:\n",
    "                break\n",
    "            \n",
    "    # combine all html pages into a single string\n",
    "    combined_html = \"<div>\" + \"\".join(html_amazon) + \"</div>\"\n",
    "    \n",
    "    # quit WebDriver session\n",
    "    driver.quit()\n",
    "    \n",
    "    # Prettyfying the html\n",
    "    soup_amazon = BeautifulSoup(combined_html, 'lxml')\n",
    "    \n",
    "    # CREATING A FOR-LOOP THAT WILL EXTRACT LAPTOP DETAILS WITHIN A PRICE RANGE OF R10000 AND R20000, THEN...\n",
    "    # STORE THEM AS A DATAFRAME\n",
    "\n",
    "    # initialize an empty list to store the Amazon laptop data\n",
    "    amazon_data = []\n",
    "\n",
    "    # extracting details for all laptops\n",
    "    laptops_details = soup_amazon.find_all('div', class_ = 'a-section a-spacing-small puis-padding-left-small puis-padding-right-small')\n",
    "    # grid-y gap-1 product-card-module_product-details-container_3ntEA\n",
    "\n",
    "    # Define price range\n",
    "    min_price = 10000\n",
    "    max_price = 20000\n",
    "\n",
    "    # for-loop\n",
    "    for laptop_deets in laptops_details:\n",
    "        # extracting laptop name from 'laptop_details' object\n",
    "        # .text if you just want the text\n",
    "        name = laptop_deets.find('h2', class_ = 'a-size-base-plus a-spacing-none a-color-base a-text-normal')\n",
    "        name = name.text if name else \"None\"\n",
    "        # extracting laptop brand from 'laptop_details' object\n",
    "        #~brand = laptop_deets.find('a', href=re.compile(r'Brand'))\n",
    "        #~brand = brand.text if brand else \"None\"\n",
    "        # extracting text and numerical (for subsetting) laptop price from 'laptop_details' object\n",
    "        price = laptop_deets.find('span', class_ = 'a-price-whole')\n",
    "        price_text = 'R ' + price.text.replace('.', '') if price else \"None\"\n",
    "        if price:\n",
    "            price_stripped = re.sub(r'\\D', '', price.text)\n",
    "            price_numerical = int(price_stripped)\n",
    "        # printing laptop stock status \n",
    "        stock_status = \"click link to view\"\n",
    "        # extracting link for laptop\n",
    "        link = laptop_deets.find('a', class_ = 'a-link-normal s-line-clamp-4 s-link-style a-text-normal')\n",
    "        link = 'https://www.amazon.co.za' + link.get('href') if link else \"No link\"\n",
    "\n",
    "        # filter laptops within price range and create dictionary output\n",
    "        if price and min_price <= price_numerical <= max_price:\n",
    "            #print(f'''\n",
    "            #Name: {name}\n",
    "            #Price: {price_text}\n",
    "            #Stock status: {stock_status}\n",
    "            #Link: {link}\n",
    "            #''')\n",
    "            amazon_data.append({\n",
    "                'Name': name,\n",
    "                'Price': price_text,\n",
    "                'Stock status': stock_status,\n",
    "                'Link': link\n",
    "            })\n",
    "\n",
    "            # print line space as separator between laptop details\n",
    "            #print('')\n",
    "\n",
    "    # convert list of dictionaries into a Pandas dataframe\n",
    "    amazon_df = pd.DataFrame(amazon_data)\n",
    "\n",
    "    # display the dataframe\n",
    "    return amazon_df   \n",
    "\n",
    "# run function (will take a minute or two)\n",
    "amazon_laptop = get_amazon_laptop()\n",
    "\n",
    "# creating a column with normalized names for takealot dataframe\n",
    "takealot_laptop['Name Normalized'] = takealot_laptop['Name'].str.lower().str.strip().str.replace(\"|\", \"\")\n",
    "\n",
    "# creating a column with normalized names for amazon dataframe\n",
    "amazon_laptop['Name Normalized'] = amazon_laptop['Name'].str.lower().str.strip().str.replace(\"|\", \"\")\n",
    "\n",
    "# Perform a merge on 'Name Normalized'\n",
    "linked_data = pd.merge(takealot_laptop, amazon_laptop, on='Name Normalized', suffixes=('_takealot', '_amazon'))\n",
    "\n",
    "# FUZZY MATCHING\n",
    "\n",
    "# create a list of names from Takealot data's 'Name Normalized' column as a 'matching dictionary'\n",
    "takealot_names = takealot_laptop['Name Normalized'].tolist()\n",
    "\n",
    "# create fuzzy matching function\n",
    "def match_names(row, name_dict, threshold):\n",
    "    match = process.extractOne(row['Name Normalized'], name_dict, scorer=fuzz.token_sort_ratio)\n",
    "    if match and match[1] > threshold: # check if similarity meets threshold\n",
    "        return match[0], match[1] # return matched name and similarity if condition is met\n",
    "    else:\n",
    "        return None, None # return 'None' if condition is not met\n",
    "\n",
    "# applying fuzzy matching function to Amazon's 'Normalized Name' column using apply() method on row-by-row basis\n",
    "amazon_laptop[[\"Match\", \"Match Similarity\"]] = amazon_laptop.apply(\n",
    "    lambda row: pd.Series(match_names(row, name_dict=takealot_names, threshold=90)), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Merge the dataframes\n",
    "# pd.merge() does exact matching; the match_names function gives approximate matches keys that exact matches would have.\n",
    "fuzzy_linked_data = pd.merge(\n",
    "    takealot_laptop,\n",
    "    amazon_laptop,\n",
    "    left_on='Name Normalized',\n",
    "    right_on='Match',\n",
    "    suffixes=('_takealot', '_amazon')\n",
    ")\n",
    "\n",
    "# remove unnecessary columns for the aesthetic\n",
    "fuzzy_linked_data.drop(columns=['Name Normalized_takealot',\n",
    "                                'Name Normalized_amazon',\n",
    "                                'Match'], inplace=True\n",
    "                      )\n",
    "\n",
    "fuzzy_linked_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc7a73b-3d14-4c5d-a8fe-a50cc58ca856",
   "metadata": {},
   "source": [
    "The following code saves the dataframe as an Excel file if required (PC local path must be specified):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d429e37-367f-46d6-9eb0-c05ac0a78a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn final arbitrage dataframe to Excel file (enter desired path + file-save-name in 'pathsave' object)\n",
    "pathsave = 'C:\\\\Users\\\\mufar\\\\Downloads\\\\Laptop Arbitrage.xlsx'\n",
    "fuzzy_linked_data.to_excel(pathsave, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
